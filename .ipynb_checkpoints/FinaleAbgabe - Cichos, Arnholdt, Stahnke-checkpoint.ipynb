{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import stuff & things\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support-Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convenient function to output test items\n",
    "def show_test_item(clf, i, text=True, classify=True):\n",
    "    a = 'actual: ' + str(test.iloc[i].recommended)\n",
    "    p = ''\n",
    "    if classify:\n",
    "        p = ' / predicted: ' + str(clf.predict(vectorizer.transform([test.iloc[i].content_text]))[0])\n",
    "    print('[' + str(i) + '] ' +a + p)\n",
    "    if text:\n",
    "        print('\\n')\n",
    "        print(test.iloc[i].content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_tagger(tagger, text):\n",
    "    sentences = sent_detector.tokenize(text)\n",
    "    return [tagger.tag(re.findall('(\\w+)', sentence)) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Input Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/juliusstahnke/Documents/HTW/Analytics/Analytics/Aufgabe4/'\n",
    "filename = 'classifier-based-german-pos-tagger.pickle'\n",
    "with open(path + filename, 'rb') as f:\n",
    "    tagger = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_detector = nltk.data.load('tokenizers/punkt/german.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Datasets for all Areas\n",
    "dir = '/Users/juliusstahnke/Documents/HTW/Analytics/Analytics/Aufgabe4'\n",
    "games = pd.read_json(dir + '/games/games.json', orient='records', encoding='utf8')\n",
    "music = pd.read_json(dir + '/music/music.json', orient='records', encoding='utf8')\n",
    "apps = pd.read_json(dir + '/apps/apps.json', orient='records', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set Randomn State\n",
    "random_state = 100\n",
    "\n",
    "#Set Traindata for games\n",
    "train_games_positiv = games[games.recommended==True].sample(frac=0.8, random_state=random_state)\n",
    "train_games_negativ = games[games.recommended==False].sample(frac=0.8, random_state=random_state)\n",
    "train_games = pd.concat([train_games_positiv, train_games_negativ])\n",
    "test_games = games.drop(train_games.index)\n",
    "\n",
    "#Set Traindata for music\n",
    "train_music_positiv = music[music.rating.isin(['8', '9', '10', '11', '12', '13', '14', '15'])].sample(frac=0.8, random_state=random_state)\n",
    "train_music_negativ = music[music.rating.isin(['1', '2', '3', '4', '5', '6', '7'])].sample(frac=0.8, random_state=random_state)\n",
    "train_music = pd.concat([train_music_positiv, train_music_negativ])\n",
    "test_music = music.drop(train_music.index)\n",
    "\n",
    "#Set Traindata for apps\n",
    "train_apps_positiv = apps[apps.Rating >= 3].sample(frac=0.8, random_state=random_state)\n",
    "train_apps_negativ = apps[apps.Rating < 3].sample(frac=0.8, random_state=random_state)\n",
    "train_apps = pd.concat([train_apps_positiv, train_apps_negativ])\n",
    "test_apps = apps.drop(train_apps.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Tableformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliusstahnke/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:31: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/juliusstahnke/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:40: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/Users/juliusstahnke/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#NOTE: THIS CAN NOT BE RUN TWICE!\n",
    "#YOU HAVE TO RELOAD THE FILES TO RUN THIS AGAIN!\n",
    "\n",
    "#####################################################\n",
    "#############GAMES###################################\n",
    "#####################################################\n",
    "\n",
    "#Einfügen positiv Spalte und Text\n",
    "#games.reset_index(inplace=True)\n",
    "train_games['Positiv'] = (games.recommended)\n",
    "train_games['Text'] = (games.content_text)\n",
    "\n",
    "#Delete the old Columns\n",
    "del train_games['content_text']\n",
    "del train_games['recommended']\n",
    "\n",
    "#Einfügen positiv Spalte und Text\n",
    "#games.reset_index(inplace=True)\n",
    "test_games['Positiv'] = (games.recommended)\n",
    "test_games['Text'] = (games.content_text)\n",
    "\n",
    "#Delete the old Columns\n",
    "del test_games['content_text']\n",
    "del test_games['recommended']\n",
    "\n",
    "#######################################################\n",
    "#############APPS######################################\n",
    "#######################################################\n",
    "\n",
    "#Einfügen positiv Spalte und Text\n",
    "train_apps = train_apps[apps.Rating!=3]\n",
    "#train_apps.reset_index(inplace=True)\n",
    "train_apps['Positiv'] = (apps.Rating > 3)\n",
    "\n",
    "#Delete the old Columns\n",
    "del train_apps['Heading']\n",
    "del train_apps['Rating']\n",
    "\n",
    "#Einfügen positiv Spalte und Text\n",
    "test_apps = test_apps[apps.Rating!=3]\n",
    "#test_apps.reset_index(inplace=True)\n",
    "test_apps['Positiv'] = (apps.Rating > 3)\n",
    "\n",
    "#Delete the old Columns\n",
    "del test_apps['Heading']\n",
    "del test_apps['Rating']\n",
    "\n",
    "############################################################\n",
    "############MUSIC###########################################\n",
    "############################################################\n",
    "\n",
    "#Einfügen positiv Spalte und Text\n",
    "train_music['Text'] = (music.description + music.summary)\n",
    "#train_music.reset_index(inplace=True)\n",
    "train_music['Positiv'] = (music.rating.isin(['8', '9', '10', '11', '12', '13', '14', '15']))\n",
    "\n",
    "#Delete the old \n",
    "del train_music['description']\n",
    "del train_music['rating']\n",
    "del train_music['summary']\n",
    "\n",
    "#Einfügen positiver Spalten und Texte\n",
    "test_music['Text'] = (music.description + music.summary)\n",
    "#test_music.reset_index(inplace=True)\n",
    "test_music['Positiv'] = (music.rating.isin(['8', '9', '10', '11', '12', '13', '14', '15']))\n",
    "\n",
    "del test_music['description']\n",
    "del test_music['rating']\n",
    "del test_music['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer Games untagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75987306064880111"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer Games\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(train_games.Text)\n",
    "\n",
    "X = vectorizer.transform(train_games.Text)\n",
    "y = train_games.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_games.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_games.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_games_tagged = [raw_tagger(tagger, a) for a in train_games.content_text]\n",
    "\n",
    "#train_games_tagged\n",
    "\n",
    "#PICKLE THE RESULT OF THIS STEP! THIS RUNS FOREVER!\n",
    "#Here is how you pickle something:\n",
    "#with open('games_pos_tagged.pickle', 'wb') as fp:\n",
    "#    pickle.dump(train_games_tagged, fp)\n",
    "    \n",
    "#If you want to load your pickled stuff use the following: \n",
    "with open('games_pos_tagged.pickle', 'rb') as fp: \n",
    "    train_games_tagged = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare result variabe\n",
    "result_games_adja = []\n",
    "\n",
    "#For every document (Needed because Reviews Contain more than one Sentence)\n",
    "for document in train_games_tagged: \n",
    "    result_doc = \"\"\n",
    "    #Check in Every Sentence (Needed Because Senteces have more than one word)\n",
    "    for sentence in document:\n",
    "        result_sen = \"\"\n",
    "        #Check if the Second Element of the Wordtupel fullfills Condition\n",
    "        for word in sentence:\n",
    "            if word[1] == 'ADJA':\n",
    "                #If so add it to Sentence, else dont\n",
    "                result_sen = result_sen + \" \" + word[0]\n",
    "        #If Sentence contains words that fullfill Condition add it to document, else dont \n",
    "        if len(result_sen) != 0:        \n",
    "            result_doc = result_doc + result_sen\n",
    "    #Add Document to Result (No Check if emty because we want reprensentation for every review in Trainingsdata)\n",
    "    result_games_adja.append(result_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize for filtert adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55835684062059243"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer Games\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(result_games_adja)\n",
    "\n",
    "X = vectorizer.transform(result_games_adja)\n",
    "y = train_games.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_games.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_games.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for Adjectivs, adverbs, nouns and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare result variabe\n",
    "result_games_multiple = []\n",
    "\n",
    "#For every document (Needed because Reviews Contain more than one Sentence)\n",
    "for document in train_games_tagged: \n",
    "    result_doc = \"\"\n",
    "    #Check in Every Sentence (Needed Because Senteces have more than one word)\n",
    "    for sentence in document:\n",
    "        result_sen = \"\"\n",
    "        #Check if the Second Element of the Wordtupel fullfills Condition\n",
    "        for word in sentence:\n",
    "            if word[1] == 'ADJA' or word[1] == 'ADV' or word[1] == 'NN' or 'VV' in word[1]:\n",
    "                #If so add it to Sentence, else dont\n",
    "                result_sen = result_sen + \" \" + word[0]\n",
    "        #If Sentence contains words that fullfill Condition add it to document, else dont \n",
    "        if len(result_sen) != 0:        \n",
    "            result_doc = result_doc + result_sen\n",
    "    #Add Document to Result (No Check if emty because we want reprensentation for every review in Trainingsdata)\n",
    "    result_games_multiple.append(result_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for Adjectivs, adverbs, nouns and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71738363892806767"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer Games\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(result_games_multiple)\n",
    "\n",
    "X = vectorizer.transform(result_games_multiple)\n",
    "y = train_games.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_games.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_games.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Apps Untagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8640573648043024"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=105, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(train_apps.Text)\n",
    "\n",
    "X = vectorizer.transform(train_apps.Text)\n",
    "y = train_apps.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_apps.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_apps.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_apps_tagged = [raw_tagger(tagger, a) for a in train_apps.Text]\n",
    "\n",
    "train_apps_tagged\n",
    "\n",
    "#PICKLE THE RESULT OF THIS STEP! THIS RUNS FOREVER!\n",
    "#Here is how you pickle something:\n",
    "with open('apps_pos_tagged.pickle', 'wb') as fp:\n",
    "    pickle.dump(train_apps_tagged, fp)\n",
    "    \n",
    "#If you want to load your pickled stuff use the following: \n",
    "#with open('games_pos_tagged.pickle', 'rb') as fp: \n",
    "#    test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for adjectivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare result variabe\n",
    "result_apps_adja = []\n",
    "\n",
    "#For every document (Needed because Reviews Contain more than one Sentence)\n",
    "for document in train_apps_tagged: \n",
    "    result_doc = \"\"\n",
    "    #Check in Every Sentence (Needed Because Senteces have more than one word)\n",
    "    for sentence in document:\n",
    "        result_sen = \"\"\n",
    "        #Check if the Second Element of the Wordtupel fullfills Condition\n",
    "        for word in sentence:\n",
    "            if word[1] == 'ADJA':\n",
    "                #If so add it to Sentence, else dont\n",
    "                result_sen = result_sen + \" \" + word[0]\n",
    "        #If Sentence contains words that fullfill Condition add it to document, else dont \n",
    "        if len(result_sen) != 0:        \n",
    "            result_doc = result_doc + result_sen\n",
    "    #Add Document to Result (No Check if emty because we want reprensentation for every review in Trainingsdata)\n",
    "    result_apps_adja.append(result_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85957573946818044"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer apps\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(result_apps_adja)\n",
    "\n",
    "X = vectorizer.transform(result_apps_adja)\n",
    "y = train_apps.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_apps.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_apps.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for Adjectivs, adverbs, nouns and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare result variabe\n",
    "result_apps_multiple = []\n",
    "\n",
    "#For every document (Needed because Reviews Contain more than one Sentence)\n",
    "for document in train_apps_tagged: \n",
    "    result_doc = \"\"\n",
    "    #Check in Every Sentence (Needed Because Senteces have more than one word)\n",
    "    for sentence in document:\n",
    "        result_sen = \"\"\n",
    "        #Check if the Second Element of the Wordtupel fullfills Condition\n",
    "        for word in sentence:\n",
    "            if word[1] == 'ADJA' or word[1] == 'ADV' or word[1] == 'NN' or 'VV' in word[1]:\n",
    "                #If so add it to Sentence, else dont\n",
    "                result_sen = result_sen + \" \" + word[0]\n",
    "        #If Sentence contains words that fullfill Condition add it to document, else dont \n",
    "        if len(result_sen) != 0:        \n",
    "            result_doc = result_doc + result_sen\n",
    "    #Add Document to Result (No Check if emty because we want reprensentation for every review in Trainingsdata)\n",
    "    result_apps_multiple.append(result_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for Adjectivs, adverbs, nouns and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88467284135046309"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer Apps\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(result_apps_multiple)\n",
    "\n",
    "X = vectorizer.transform(result_apps_multiple)\n",
    "y = train_apps.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_apps.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_apps.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Music Untagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49523396880415943"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(train_music.Text)\n",
    "\n",
    "X = vectorizer.transform(train_music.Text)\n",
    "y = train_music.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_music.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_music.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_music_tagged = [raw_tagger(tagger, a) for a in train_music.Text]\n",
    "\n",
    "#train_music_tagged\n",
    "\n",
    "#PICKLE THE RESULT OF THIS STEP! THIS RUNS FOREVER!\n",
    "#Here is how you pickle something:\n",
    "#with open('music_pos_tagged.pickle', 'wb') as fp:\n",
    "    #pickle.dump(train_music_tagged, fp)\n",
    "    \n",
    "#If you want to load your pickled stuff use the following: \n",
    "with open('music_pos_tagged.pickle', 'rb') as fp:\n",
    "    train_music_tagged = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for Adjectiv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declare result variabe\n",
    "result_music_adja = []\n",
    "\n",
    "#For every document (Needed because Reviews Contain more than one Sentence)\n",
    "for document in train_music_tagged: \n",
    "    result_doc = \"\"\n",
    "    #Check in Every Sentence (Needed Because Senteces have more than one word)\n",
    "    for sentence in document:\n",
    "        result_sen = \"\"\n",
    "        #Check if the Second Element of the Wordtupel fullfills Condition\n",
    "        for word in sentence:\n",
    "            if word[1] == 'ADJA':\n",
    "                #If so add it to Sentence, else dont\n",
    "                result_sen = result_sen + \" \" + word[0]\n",
    "        #If Sentence contains words that fullfill Condition add it to document, else dont \n",
    "        if len(result_sen) != 0:        \n",
    "            result_doc = result_doc + result_sen\n",
    "    #Add Document to Result (No Check if emty because we want reprensentation for every review in Trainingsdata)\n",
    "    result_music_adja.append(result_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for Adjectiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.485051993067591"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer music\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(result_music_adja)\n",
    "\n",
    "X = vectorizer.transform(result_music_adja)\n",
    "y = train_music.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_music.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_music.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for Adjectivs, adverbs, nouns and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declare result variabe\n",
    "result_music_multiple = []\n",
    "\n",
    "#For every document (Needed because Reviews Contain more than one Sentence)\n",
    "for document in train_music_tagged: \n",
    "    result_doc = \"\"\n",
    "    #Check in Every Sentence (Needed Because Senteces have more than one word)\n",
    "    for sentence in document:\n",
    "        result_sen = \"\"\n",
    "        #Check if the Second Element of the Wordtupel fullfills Condition\n",
    "        for word in sentence:\n",
    "            if word[1] == 'ADJA' or word[1] == 'ADV' or word[1] == 'NN' or 'VV' in word[1]:\n",
    "                #If so add it to Sentence, else dont\n",
    "                result_sen = result_sen + \" \" + word[0]\n",
    "        #If Sentence contains words that fullfill Condition add it to document, else dont \n",
    "        if len(result_sen) != 0:        \n",
    "            result_doc = result_doc + result_sen\n",
    "    #Add Document to Result (No Check if emty because we want reprensentation for every review in Trainingsdata)\n",
    "    result_music_multiple.append(result_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for Adjectivs, adverbs, nouns and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49718370883882151"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer music\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(result_music_multiple)\n",
    "\n",
    "X = vectorizer.transform(result_music_multiple)\n",
    "y = train_music.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_music.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_music.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegEx Hilfsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addNegation(str):\n",
    "    findNot = re.compile('(nicht.*?[,.!?:()])')\n",
    "    findBegining = re.compile('(^|\\s+)')\n",
    "\n",
    "    str = re.split(findNot, str)\n",
    "    i = 1\n",
    "\n",
    "    while (i < len(str)-1):\n",
    "        rstr = str[i][6:-1]\n",
    "        newstr = re.sub(findBegining, \" not_\", rstr)\n",
    "        str[i] = str[i].replace(\" \" + rstr, newstr)\n",
    "        i = i+2\n",
    "    \n",
    "    result = ''\n",
    "    for i in range(len(str)):\n",
    "        result = result + str[i]\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Negation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_games_negated = [addNegation(str) for str in train_games.Text]    \n",
    "test_games_negated = [addNegation(str) for str in test_games.Text] \n",
    "\n",
    "train_apps_negated = [addNegation(str) for str in train_apps.Text]    \n",
    "test_apps_negated = [addNegation(str) for str in test_apps.Text] \n",
    "\n",
    "train_music_negated = [addNegation(str) for str in train_music.Text]    \n",
    "test_music_negated = [addNegation(str) for str in test_music.Text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for Negated Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76480959097320167"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer games\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(train_games_negated)\n",
    "\n",
    "X = vectorizer.transform(train_games_negated)\n",
    "y = train_games.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_games.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_games_negated))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for Negated Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89483119211233941"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer apps\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(train_apps_negated)\n",
    "\n",
    "X = vectorizer.transform(train_apps_negated)\n",
    "y = train_apps.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_apps.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_apps_negated))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for Negated Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4948006932409012"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer music\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(train_music_negated)\n",
    "\n",
    "X = vectorizer.transform(train_music_negated)\n",
    "y = train_music.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_music.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_music_negated))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concat all three datasets\n",
    "train_data_unified = pd.concat([train_games, train_apps, train_music])\n",
    "test_data_unified = pd.concat([test_games, test_apps, test_music])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize for all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63021635496883022"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer all\n",
    "vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "vectorizer.fit(train_data_unified.Text)\n",
    "\n",
    "X = vectorizer.transform(train_data_unified.Text)\n",
    "y = train_data_unified.Positiv\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_data_unified.Positiv\n",
    "predicted = clf.predict(vectorizer.transform(test_data_unified.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Source to Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliusstahnke/miniconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train_games['Source'] = \"Games\"\n",
    "test_games['Source'] = \"Games\"\n",
    "\n",
    "train_apps['Source'] = \"Apps\"\n",
    "test_apps['Source'] = \"Apps\"\n",
    "\n",
    "train_music['Source'] = \"Music\"\n",
    "test_music['Source'] = \"Music\"\n",
    "\n",
    "#Concat all three datasets\n",
    "train_data_sourced = pd.concat([train_games, train_apps, train_music])\n",
    "test_data_sourced = pd.concat([test_games, test_apps, test_music])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Vectorizer all\n",
    "source_vectorizer = CountVectorizer(min_df=10, max_df=200, token_pattern='\\w+')\n",
    "source_vectorizer.fit(train_data_sourced.Text)\n",
    "\n",
    "X = source_vectorizer.transform(train_data_sourced.Text)\n",
    "y = train_data_sourced.Source\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "actuals = test_data_sourced.Source\n",
    "predicted = clf.predict(source_vectorizer.transform(test_data_sourced.Text))\n",
    "accuracy_score(actuals, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-1a62a68e33b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msource_annotated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_sourced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'source_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "source_annotated = clf.predict(source_vectorizer.transform(train_data_sourced.Text))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
